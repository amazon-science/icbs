{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a10eff2-2c21-4f37-bf5e-9f4e78f8ff5f",
   "metadata": {},
   "source": [
    "Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved. <br>\n",
    "SPDX-License-Identifier: CC-BY-NC-4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1496be-bc4d-4068-86e4-e670a5dc532a",
   "metadata": {},
   "source": [
    "# Simple Example (LLM)\n",
    "\n",
    "This example shows how to prune an LLM, using a pretrained model and dataset from Hugging Face. By nature LLMs are large, so it is not possible to prune them quickly for the purposes of a demo, nor without access to a GPU (or multiple). For this reason, this example shows how to prune a tiny LLM with arbitrary weights. To prune a \"real\" LLM, you'll need run this code on an instance with an appropriate number of GPUs and memory, for a number of hours or days. The settings that should be changed to get the settings we used in the paper for Mistral-7B are indicated after the # sign, where a change is needed. \n",
    "\n",
    "Some aspects of this example are specific to LLMs, such as the loading of the model, preparation of the data, and the evaluation of the model. If your model is not an LLM, `simple_example.ipynb` may be a better starting point. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1d5ea7-2f72-401f-8ce3-5b9ef1765193",
   "metadata": {},
   "source": [
    "## Language model evaluation harness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0e5623-6653-412b-827d-40bdb9afc028",
   "metadata": {},
   "source": [
    "To run this example, please make sure to install the LM Evaluation Harness first:\n",
    "```\n",
    "git clone https://github.com/EleutherAI/lm-evaluation-harness\n",
    "cd lm-evaluation-harness\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74120102-36a0-4dad-8b94-77ebe3ebf0e3",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "770016af-f57b-440a-a0f0-7b730691c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from icbs.evaluation import evaluate_model, evaluate_model_tasks\n",
    "from icbs.loops import prune_loop\n",
    "from icbs.pruner import Pruner\n",
    "from icbs.solvers import ConstrainedSASolver\n",
    "from icbs.util import calc_density, get_log_w_names_step, get_named_weights\n",
    "from icbs.util_llm import is_llm, load_llm, prep_loader_batch, prepare_llm\n",
    "from util import load_dataset, set_num_threads, set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fbebd5-c6a6-41eb-aa43-6a91911ed82e",
   "metadata": {},
   "source": [
    "### Settings\n",
    "\n",
    "Some settings are chosen specifically so that this notebook can be run in a short time.  In such cases, the settings used for the LLMs in the paper are included after the # symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669c3d04-b1af-46ee-b21b-80d56f82fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and dataset\n",
    "model_name = \"stas/tiny-random-llama-2\"  # \"mistralai/Mistral-7B-v0.1\"\n",
    "dataset_name = \"stas/c4-en-10k\"  # \"allenai/c4\"\n",
    "dataset_args = {}  # {\"streaming\": True, \"name\": \"en\"}\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Pruner parameters\n",
    "seed = 43\n",
    "density = 0.3\n",
    "pruner_num_epochs = 5  # 10\n",
    "num_steps_per_epoch = 1  # 300\n",
    "init_method = \"magnitude\"  # \"wanda_per_output\"\n",
    "block_size = 128  # 4096\n",
    "num_restarts = 1  # 20\n",
    "min_num_steps_per_layer = 1  # 10\n",
    "selection_method = \"gradient\"\n",
    "calc_hessian_method = \"gradient_per_sample\"\n",
    "grad_multiplier = 0.75\n",
    "ridge_multiplier = 0.001\n",
    "verbose = 2\n",
    "\n",
    "# Batch sizes\n",
    "batch_size_evaluation = 64  # 1\n",
    "batch_size_pruning = 16\n",
    "batch_size_calibration = 64  # 128\n",
    "max_batch_size = 1\n",
    "\n",
    "# Block settings\n",
    "block_solver = ConstrainedSASolver(verbose=verbose, num_restarts=num_restarts)\n",
    "k = block_size // 2\n",
    "tabu_frac = 0.40\n",
    "fix_frac_prune = 0.42\n",
    "fix_frac_keep = 0.35\n",
    "\n",
    "# Workers, etc.\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "dataloader_args = {\n",
    "    \"num_workers\": 4 if torch.cuda.is_available() else 0,\n",
    "    \"pin_memory\": False,\n",
    "}\n",
    "\n",
    "# Only prune linear layers and do not prune the final layer\n",
    "keep_layers = (torch.nn.Linear,)\n",
    "layer_name_to_exclude = \"lm_head\"\n",
    "\n",
    "# The loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Evaluation\n",
    "evaluate_model_tasks_args = {\n",
    "    \"tasks\": [\"hellaswag\"],\n",
    "    # [\"boolq\", \"rte\", \"hellaswag\", \"winogrande\", \"arc_easy\", \"arc_challenge\", \"openbookqa\"]\n",
    "    \"num_fewshot\": 0,  # This is zero-shot evaluation\n",
    "    \"limit\": 10,  # None\n",
    "    \"check_integrity\": False,\n",
    "    \"use_cache\": None,  # Do not cache model responses\n",
    "    \"random_seed\": None,  # Do not set random seeds - we handle that already\n",
    "    \"numpy_random_seed\": None,\n",
    "    \"torch_random_seed\": None,\n",
    "    \"fewshot_random_seed\": None,\n",
    "}\n",
    "\n",
    "# Set the number of threads and seed the random number generator\n",
    "set_num_threads(num_cpus)\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905b9449-4d94-4459-9fe0-20fe1d672cd8",
   "metadata": {},
   "source": [
    "## Load a model\n",
    "\n",
    "When running on a machine with multiple GPUs, the print out below this cell will show the distribution of the model across GPUs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af91c99b-d3c6-476d-9c64-37a9a62c0644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device map: {'': device(type='cpu')}\n"
     ]
    }
   ],
   "source": [
    "# Load a fresh model\n",
    "# Note: it's important to load the model before getting a reference\n",
    "# to the weights (below)\n",
    "model = load_llm(model_name, device)\n",
    "model, tokenizer, seqlen, input_device = prepare_llm(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aae94fd-4573-4ffd-93b3-600b414efe05",
   "metadata": {},
   "source": [
    "Choose which layer to prune at each step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c268e15-4c56-42b5-ba3a-bad478dc3bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 14 layers\n",
      "WARNING: cannot adhere to min_num_steps - some layers will have a lower number of steps\n"
     ]
    }
   ],
   "source": [
    "# The list of layers to process\n",
    "named_weights = get_named_weights(model, keep_layers)\n",
    "named_weights = {\n",
    "    name: weights\n",
    "    for name, weights in named_weights.items()\n",
    "    if layer_name_to_exclude not in name\n",
    "}\n",
    "layer_names = list(named_weights.keys())\n",
    "print(f\"Pruning {len(layer_names)} layers\")\n",
    "\n",
    "# The distribution of steps to weights\n",
    "w_names_step = get_log_w_names_step(\n",
    "    named_weights, num_steps_per_epoch, min_num_steps_per_layer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ac1ec9-b2a4-45c5-ad30-5d776cdab39d",
   "metadata": {},
   "source": [
    "## Load a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f2b86c-f0fd-4648-84fc-0b2c767997a2",
   "metadata": {},
   "source": [
    "Now, let's load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6891d8bc-6c25-48c4-b34f-6cba2861eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = load_dataset(dataset_name, **dataset_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207695a2-7ab0-4bf1-85ac-c3cc3102e54c",
   "metadata": {},
   "source": [
    "Then we set up data loaders for pruning and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c342bc53-9487-490c-9b62-df78f43539e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning dataloader\n",
    "prune_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size_pruning,\n",
    "    shuffle=False,\n",
    "    **dataloader_args,\n",
    ")\n",
    "prune_dataloader.tokenizer = tokenizer  # Inject tokenizer to allow downstream use\n",
    "\n",
    "# Data loader\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=batch_size_evaluation,\n",
    "    shuffle=False,\n",
    "    **dataloader_args,\n",
    ")\n",
    "valid_dataloader.tokenizer = tokenizer  # Inject tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e9fe95-3b41-406e-a74f-1c81343ed62f",
   "metadata": {},
   "source": [
    "If the initial selection of weights to prune is done using Wanda or the Gradient option, then we also need to provide the calibaration data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "463f0b77-0e29-4da2-9c61-faf09ff5c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if init_method.startswith(\"wanda\") or init_method.startswith(\"gradient\"):\n",
    "    calibration_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size_calibration,\n",
    "        shuffle=False,  # Set to True for any dataset that is not streamed\n",
    "        **dataloader_args,\n",
    "    )\n",
    "    calibration_dataloader.tokenizer = tokenizer  # Inject tokenizer\n",
    "    calibration_loader_batch = next(iter(calibration_dataloader))\n",
    "    X_init, y_init = prep_loader_batch(calibration_loader_batch, tokenizer, seqlen)\n",
    "else:\n",
    "    X_init, y_init = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f04c3a-5763-4760-adb9-d0bd717753d8",
   "metadata": {},
   "source": [
    "## Evaluate the model (before pruning)\n",
    "\n",
    "We check the performance of the model before pruning, as a point of reference: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3c9b3a0-35a9-4159-a728-89e12c92bf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05:17:11:09,070 WARNING  [huggingface.py:96] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "2024-11-05:17:11:09,071 INFO     [huggingface.py:483] Using model type 'default'\n",
      "2024-11-05:17:11:09,073 WARNING  [huggingface.py:277] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "2024-11-05:17:11:09,076 INFO     [evaluator.py:217] Using pre-initialized model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model before pruning:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05:17:11:09,822 DEBUG    [__init__.py:522] File _phrases_va_common.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/catalan_bench/phrases_va could not be loaded\n",
      "2024-11-05:17:11:12,873 DEBUG    [__init__.py:522] File _phrases_es_common.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/spanish_bench/phrases_es could not be loaded\n",
      "2024-11-05:17:11:25,266 DEBUG    [__init__.py:522] File winogenerated.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/model_written_evals/winogenerated could not be loaded\n",
      "2024-11-05:17:11:35,818 WARNING  [evaluator.py:270] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-11-05:17:11:35,820 DEBUG    [cache.py:33] requests-hellaswag-0shot-rank0-world_size1-tokenizer is not cached, generating...\n",
      "2024-11-05:17:11:35,821 INFO     [task.py:415] Building contexts for hellaswag on rank 0...\n",
      "100%|█████████████████████████████████████████| 10/10 [00:00<00:00, 1775.22it/s]\n",
      "2024-11-05:17:11:35,841 DEBUG    [evaluator.py:460] Task: hellaswag; number of requests on this rank: 40\n",
      "2024-11-05:17:11:35,842 INFO     [evaluator.py:489] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|██████████| 40/40 [00:00<00:00, 189.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for each task:\n",
      "    hellaswag : 30.000 (+-15.275)\n",
      "  Evaluation time: evaluation_time=31.3sec, Accuracy: 30.00% (+-15.28%)\n",
      "Initial evaluation took: 0.52min\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating model before pruning:\")\n",
    "unpruned_evaluation_start_time = time.time()\n",
    "unpruned_valid_accuracy, unpruned_evaluation_time, _ = evaluate_model_tasks(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    verbose=True if verbose else False,\n",
    "    batch_size=batch_size_evaluation,\n",
    "    device=device,\n",
    "    **evaluate_model_tasks_args,\n",
    ")\n",
    "unpruned_evaluation_time = time.time() - unpruned_evaluation_start_time\n",
    "print(f\"Initial evaluation took: {unpruned_evaluation_time/60:.2f}min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53e86a8-4fd1-4d21-b20a-d3ea0907fc1b",
   "metadata": {},
   "source": [
    "## Run "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ec32bf-cdee-44c8-9750-76ae7ecc457d",
   "metadata": {},
   "source": [
    "For demonstration purposes, the below will even run on a CPU and should take a few minutes (depending on the specs). However, we recommend running any actual experiments on a machine with at least one GPU. First we instantiate the pruner, which will already perform the initial pruning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff07e98-3b9c-40b9-8a4a-082d40ee291b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Pruning weights across all layers using density=0.3 block_solver=ConstrainedSASolver block_size=128 k=64 init_method='magnitude' selection_method='gradient' grad_multiplier=0.75 ridge_multiplier=0.001 calc_hessian_method='gradient_per_sample' seed=43 tabu_frac=0.4 fix_frac_prune=0.42 fix_frac_keep=0.35 \n",
      "\n",
      "Resetting pruner\n",
      "Performing initial pruning on layer model.layers.0.self_attn.q_proj.weight\n",
      "w_name='model.layers.0.self_attn.q_proj.weight', num_weights=256, self.density=0.3, num_fix_keep=27, num_fix_prune=75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05:17:11:40,612 WARNING  [huggingface.py:96] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "2024-11-05:17:11:40,613 INFO     [huggingface.py:483] Using model type 'default'\n",
      "2024-11-05:17:11:40,615 WARNING  [huggingface.py:277] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "2024-11-05:17:11:40,617 INFO     [evaluator.py:217] Using pre-initialized model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer model.layers.0.self_attn.q_proj.weight cannot support tabu list of size 62 (tabu fraction 0.4 * num candidate weights 154), given block size 128. Switching off tabu for this layer.\n",
      "Done with initial pruning of layer model.layers.0.self_attn.q_proj.weight, layer_density=0.301\n",
      "    _perform_init_pruning_layer() took: 0.01s\n",
      "Performing initial pruning on layer model.layers.0.self_attn.k_proj.weight\n",
      "w_name='model.layers.0.self_attn.k_proj.weight', num_weights=256, self.density=0.3, num_fix_keep=27, num_fix_prune=75\n",
      "Layer model.layers.0.self_attn.k_proj.weight cannot support tabu list of size 62 (tabu fraction 0.4 * num candidate weights 154), given block size 128. Switching off tabu for this layer.\n",
      "Done with initial pruning of layer model.layers.0.self_attn.k_proj.weight, layer_density=0.301\n",
      "    _perform_init_pruning_layer() took: 0.00s\n",
      "Performing initial pruning on layer model.layers.0.self_attn.v_proj.weight\n",
      "w_name='model.layers.0.self_attn.v_proj.weight', num_weights=256, self.density=0.3, num_fix_keep=27, num_fix_prune=75\n",
      "Layer model.layers.0.self_attn.v_proj.weight cannot support tabu list of size 62 (tabu fraction 0.4 * num candidate weights 154), given block size 128. Switching off tabu for this layer.\n",
      "Done with initial pruning of layer model.layers.0.self_attn.v_proj.weight, layer_density=0.301\n",
      "    _perform_init_pruning_layer() took: 0.00s\n",
      "Performing initial pruning on layer model.layers.0.self_attn.o_proj.weight\n",
      "w_name='model.layers.0.self_attn.o_proj.weight', num_weights=256, self.density=0.3, num_fix_keep=27, num_fix_prune=75\n",
      "Layer model.layers.0.self_attn.o_proj.weight cannot support tabu list of size 62 (tabu fraction 0.4 * num candidate weights 154), given block size 128. Switching off tabu for this layer.\n",
      "Done with initial pruning of layer model.layers.0.self_attn.o_proj.weight, layer_density=0.301\n",
      "    _perform_init_pruning_layer() took: 0.00s\n",
      "Performing initial pruning on layer model.layers.0.mlp.gate_proj.weight\n",
      "w_name='model.layers.0.mlp.gate_proj.weight', num_weights=1024, self.density=0.3, num_fix_keep=107, num_fix_prune=301\n",
      "Done with initial pruning of layer model.layers.0.mlp.gate_proj.weight, layer_density=0.300\n",
      "    _perform_init_pruning_layer() took: 0.00s\n",
      "Performing initial pruning on layer model.layers.0.mlp.up_proj.weight\n",
      "w_name='model.layers.0.mlp.up_proj.weight', num_weights=1024, self.density=0.3, num_fix_keep=107, num_fix_prune=301\n",
      "Done with initial pruning of layer model.layers.0.mlp.up_proj.weight, layer_density=0.300\n",
      "    _perform_init_pruning_layer() took: 0.00s\n",
      "Performing initial pruning on layer model.layers.0.mlp.down_proj.weight\n",
      "w_name='model.layers.0.mlp.down_proj.weight', num_weights=1024, self.density=0.3, num_fix_keep=107, num_fix_prune=301\n",
      "Done with initial pruning of layer model.layers.0.mlp.down_proj.weight, layer_density=0.300\n",
      "    _perform_init_pruning_layer() took: 0.00s\n",
      "Performing initial pruning on layer model.layers.1.self_attn.q_proj.weight\n",
      "w_name='model.layers.1.self_attn.q_proj.weight', num_weights=256, self.density=0.3, num_fix_keep=27, num_fix_prune=75\n",
      "Layer model.layers.1.self_attn.q_proj.weight cannot support tabu list of size 62 (tabu fraction 0.4 * num candidate weights 154), given block size 128. Switching off tabu for this layer.\n",
      "Done with initial pruning of layer model.layers.1.self_attn.q_proj.weight, layer_density=0.301\n",
      "    _perform_init_pruning_layer() took: 0.00s\n",
      "Performing initial pruning on layer model.layers.1.self_attn.k_proj.weight\n",
      "w_name='model.layers.1.self_attn.k_proj.weight', num_weights=256, self.density=0.3, num_fix_keep=27, num_fix_prune=75\n",
      "Layer model.layers.1.self_attn.k_proj.weight cannot support tabu list of size 62 (tabu fraction 0.4 * num candidate weights 154), given block size 128. Switching off tabu for this layer.\n",
      "Done with initial pruning of layer model.layers.1.self_attn.k_proj.weight, layer_density=0.301\n",
      "    _perform_init_pruning_layer() took: 0.00s\n",
      "Performing initial pruning on layer model.layers.1.self_attn.v_proj.weight\n",
      "w_name='model.layers.1.self_attn.v_proj.weight', num_weights=256, self.density=0.3, num_fix_keep=27, num_fix_prune=75\n",
      "Layer model.layers.1.self_attn.v_proj.weight cannot support tabu list of size 62 (tabu fraction 0.4 * num candidate weights 154), given block size 128. Switching off tabu for this layer.\n",
      "Done with initial pruning of layer model.layers.1.self_attn.v_proj.weight, layer_density=0.301\n",
      "    _perform_init_pruning_layer() took: 0.00s\n",
      "Performing initial pruning on layer model.layers.1.self_attn.o_proj.weight\n",
      "w_name='model.layers.1.self_attn.o_proj.weight', num_weights=256, self.density=0.3, num_fix_keep=27, num_fix_prune=75\n",
      "Layer model.layers.1.self_attn.o_proj.weight cannot support tabu list of size 62 (tabu fraction 0.4 * num candidate weights 154), given block size 128. Switching off tabu for this layer.\n",
      "Done with initial pruning of layer model.layers.1.self_attn.o_proj.weight, layer_density=0.301\n",
      "    _perform_init_pruning_layer() took: 0.00s\n",
      "Performing initial pruning on layer model.layers.1.mlp.gate_proj.weight\n",
      "w_name='model.layers.1.mlp.gate_proj.weight', num_weights=1024, self.density=0.3, num_fix_keep=107, num_fix_prune=301\n",
      "Done with initial pruning of layer model.layers.1.mlp.gate_proj.weight, layer_density=0.300\n",
      "    _perform_init_pruning_layer() took: 0.00s\n",
      "Performing initial pruning on layer model.layers.1.mlp.up_proj.weight\n",
      "w_name='model.layers.1.mlp.up_proj.weight', num_weights=1024, self.density=0.3, num_fix_keep=107, num_fix_prune=301\n",
      "Done with initial pruning of layer model.layers.1.mlp.up_proj.weight, layer_density=0.300\n",
      "    _perform_init_pruning_layer() took: 0.00s\n",
      "Performing initial pruning on layer model.layers.1.mlp.down_proj.weight\n",
      "w_name='model.layers.1.mlp.down_proj.weight', num_weights=1024, self.density=0.3, num_fix_keep=107, num_fix_prune=301\n",
      "Done with initial pruning of layer model.layers.1.mlp.down_proj.weight, layer_density=0.300\n",
      "    _perform_init_pruning_layer() took: 0.00s\n",
      "Done with initial pruning in 0.02s\n",
      "Target density: 0.3 Actual density: 0.9450\n",
      "Evaluating model after initial pruning:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05:17:11:41,387 DEBUG    [__init__.py:522] File _phrases_va_common.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/catalan_bench/phrases_va could not be loaded\n",
      "2024-11-05:17:11:44,774 DEBUG    [__init__.py:522] File _phrases_es_common.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/spanish_bench/phrases_es could not be loaded\n",
      "2024-11-05:17:11:56,233 DEBUG    [__init__.py:522] File winogenerated.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/model_written_evals/winogenerated could not be loaded\n",
      "2024-11-05:17:12:05,293 WARNING  [evaluator.py:270] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-11-05:17:12:05,295 DEBUG    [cache.py:33] requests-hellaswag-0shot-rank0-world_size1-tokenizer is not cached, generating...\n",
      "2024-11-05:17:12:05,296 INFO     [task.py:415] Building contexts for hellaswag on rank 0...\n",
      "100%|█████████████████████████████████████████| 10/10 [00:00<00:00, 1813.91it/s]\n",
      "2024-11-05:17:12:05,312 DEBUG    [evaluator.py:460] Task: hellaswag; number of requests on this rank: 40\n",
      "2024-11-05:17:12:05,313 INFO     [evaluator.py:489] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|██████████| 40/40 [00:00<00:00, 264.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for each task:\n",
      "    hellaswag : 30.000 (+-15.275)\n",
      "  Evaluation time: evaluation_time=27.4sec, Accuracy: 30.00% (+-15.28%)\n",
      "Initial pruning and validation took: 0.46min\n"
     ]
    }
   ],
   "source": [
    "initial_pruning_start_time = time.time()\n",
    "\n",
    "print(\"*\" * 80)\n",
    "print(\n",
    "    f\"Pruning weights across all layers using {density=} \"\n",
    "    f\"block_solver={block_solver.__class__.__name__} \"\n",
    "    f\"{block_size=} {k=} {init_method=} {selection_method=} \"\n",
    "    f\"{grad_multiplier=} {ridge_multiplier=} {calc_hessian_method=} \"\n",
    "    f\"{seed=} {tabu_frac=} {fix_frac_prune=} {fix_frac_keep=} \\n\"\n",
    ")\n",
    "\n",
    "pruner = Pruner(\n",
    "    model,\n",
    "    loss_function,\n",
    "    density,\n",
    "    block_solver,\n",
    "    block_size,\n",
    "    k,\n",
    "    layer_names,\n",
    "    init_method,\n",
    "    selection_method,\n",
    "    grad_multiplier,\n",
    "    ridge_multiplier,\n",
    "    calc_hessian_method,\n",
    "    seed,\n",
    "    verbose,\n",
    "    X_init=X_init,\n",
    "    y_init=y_init,\n",
    "    tabu_frac=tabu_frac,\n",
    "    fix_frac_prune=fix_frac_prune,\n",
    "    fix_frac_keep=fix_frac_keep,\n",
    "    max_batch_size=max_batch_size,\n",
    ")\n",
    "\n",
    "print(f\"Target density: {density} Actual density: {calc_density(model):.4f}\")\n",
    "\n",
    "print(\"Evaluating model after initial pruning:\")\n",
    "valid_accuracy, evaluation_time, _ = evaluate_model_tasks(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    verbose=True if verbose else False,\n",
    "    batch_size=batch_size_evaluation,\n",
    "    device=device,\n",
    "    **evaluate_model_tasks_args,\n",
    ")\n",
    "\n",
    "initial_pruning_time = time.time() - initial_pruning_start_time\n",
    "print(f\"Initial pruning and validation took: {initial_pruning_time/60:.2f}min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae621f59-e292-4027-9f9e-b9e275ff6cd2",
   "metadata": {},
   "source": [
    "Then we run the optimization-based pruning steps to (hopefully) improve on the initial pruning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f01bcfe5-2cc7-441f-bbda-1e73698900ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "num_epoch=1\n",
      "-----------------------\n",
      "Pruner step 1 (of 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05:17:12:27,837 WARNING  [huggingface.py:96] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "2024-11-05:17:12:27,838 INFO     [huggingface.py:483] Using model type 'default'\n",
      "2024-11-05:17:12:27,840 WARNING  [huggingface.py:277] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "2024-11-05:17:12:27,842 INFO     [evaluator.py:217] Using pre-initialized model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Calculated gradient in 19.56s\n",
      "    w_name='model.layers.0.mlp.gate_proj.weight' k_effective=64\n",
      "    _calc_grad_sample_block() took: 0.00s\n",
      "    _calc_hess_block() took: 0.00s\n",
      "    scaling=3.010e+07 cutoff=1.000e-12 Q_density=1.00000 Q_density_cutoff=0.50421\n",
      "    Solving with ConstrainedSASolver, problem_filename=PosixPath('.98345_241105_171227700923_57a693665e14481e9497a184ecf6d291.tmp')\n",
      "    n=128 best_E=314.115 elapsed_time=0.018\n",
      "    dL=-0.000 dE=-0.000 ridge_contribution=0.000 const=-0.000 best_E=0.000 dL_eval=-0.000 delta_w_squared=0.033\n",
      "    Pruner step took: 19.76s\n",
      "\n",
      "Evaluating model after epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05:17:12:28,496 DEBUG    [__init__.py:522] File _phrases_va_common.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/catalan_bench/phrases_va could not be loaded\n",
      "2024-11-05:17:12:31,245 DEBUG    [__init__.py:522] File _phrases_es_common.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/spanish_bench/phrases_es could not be loaded\n",
      "2024-11-05:17:12:41,298 DEBUG    [__init__.py:522] File winogenerated.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/model_written_evals/winogenerated could not be loaded\n",
      "2024-11-05:17:12:48,601 WARNING  [evaluator.py:270] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-11-05:17:12:48,603 DEBUG    [cache.py:33] requests-hellaswag-0shot-rank0-world_size1-tokenizer is not cached, generating...\n",
      "2024-11-05:17:12:48,604 INFO     [task.py:415] Building contexts for hellaswag on rank 0...\n",
      "100%|█████████████████████████████████████████| 10/10 [00:00<00:00, 1924.88it/s]\n",
      "2024-11-05:17:12:48,621 DEBUG    [evaluator.py:460] Task: hellaswag; number of requests on this rank: 40\n",
      "2024-11-05:17:12:48,622 INFO     [evaluator.py:489] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|██████████| 40/40 [00:00<00:00, 274.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for each task:\n",
      "    hellaswag : 30.000 (+-15.275)\n",
      "  Evaluation time: evaluation_time=23.5sec, Accuracy: 30.00% (+-15.28%)\n",
      "  Time: prune_time=19.8sec\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "num_epoch=2\n",
      "-----------------------\n",
      "Pruner step 1 (of 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05:17:13:09,934 WARNING  [huggingface.py:96] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "2024-11-05:17:13:09,936 INFO     [huggingface.py:483] Using model type 'default'\n",
      "2024-11-05:17:13:09,938 WARNING  [huggingface.py:277] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "2024-11-05:17:13:09,940 INFO     [evaluator.py:217] Using pre-initialized model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Calculated gradient in 18.46s\n",
      "    w_name='model.layers.0.mlp.gate_proj.weight' k_effective=64\n",
      "    _calc_grad_sample_block() took: 0.00s\n",
      "    _calc_hess_block() took: 0.00s\n",
      "    scaling=4.510e+07 cutoff=1.000e-12 Q_density=1.00000 Q_density_cutoff=0.49719\n",
      "    Solving with ConstrainedSASolver, problem_filename=PosixPath('.98345_241105_171309817864_ac4e910e0f344588867ae1aa335b84c7.tmp')\n",
      "    n=128 best_E=205.037 elapsed_time=0.014\n",
      "    dL=-0.000 dE=0.000 ridge_contribution=0.000 const=0.000 best_E=0.000 dL_eval=-0.000 delta_w_squared=0.028\n",
      "    Pruner step took: 18.61s\n",
      "\n",
      "Evaluating model after epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05:17:13:10,582 DEBUG    [__init__.py:522] File _phrases_va_common.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/catalan_bench/phrases_va could not be loaded\n",
      "2024-11-05:17:13:13,400 DEBUG    [__init__.py:522] File _phrases_es_common.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/spanish_bench/phrases_es could not be loaded\n",
      "2024-11-05:17:13:23,459 DEBUG    [__init__.py:522] File winogenerated.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/model_written_evals/winogenerated could not be loaded\n",
      "2024-11-05:17:13:31,202 WARNING  [evaluator.py:270] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-11-05:17:13:31,204 DEBUG    [cache.py:33] requests-hellaswag-0shot-rank0-world_size1-tokenizer is not cached, generating...\n",
      "2024-11-05:17:13:31,205 INFO     [task.py:415] Building contexts for hellaswag on rank 0...\n",
      "100%|█████████████████████████████████████████| 10/10 [00:00<00:00, 1902.96it/s]\n",
      "2024-11-05:17:13:31,223 DEBUG    [evaluator.py:460] Task: hellaswag; number of requests on this rank: 40\n",
      "2024-11-05:17:13:31,224 INFO     [evaluator.py:489] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|██████████| 40/40 [00:00<00:00, 279.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for each task:\n",
      "    hellaswag : 30.000 (+-15.275)\n",
      "  Evaluation time: evaluation_time=23.9sec, Accuracy: 30.00% (+-15.28%)\n",
      "  Time: prune_time=18.6sec\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "num_epoch=3\n",
      "-----------------------\n",
      "Pruner step 1 (of 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05:17:13:53,157 WARNING  [huggingface.py:96] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "2024-11-05:17:13:53,159 INFO     [huggingface.py:483] Using model type 'default'\n",
      "2024-11-05:17:13:53,161 WARNING  [huggingface.py:277] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "2024-11-05:17:13:53,163 INFO     [evaluator.py:217] Using pre-initialized model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Calculated gradient in 19.17s\n",
      "    w_name='model.layers.0.mlp.gate_proj.weight' k_effective=64\n",
      "    _calc_grad_sample_block() took: 0.00s\n",
      "    _calc_hess_block() took: 0.00s\n",
      "    scaling=2.565e+07 cutoff=1.000e-12 Q_density=1.00000 Q_density_cutoff=0.50568\n",
      "    Solving with ConstrainedSASolver, problem_filename=PosixPath('.98345_241105_171353028294_d48ee326d9cf43b1a07c14933ba77c5d.tmp')\n",
      "    n=128 best_E=1.745 elapsed_time=0.025\n",
      "    dL=0.000 dE=0.000 ridge_contribution=0.000 const=0.000 best_E=0.000 dL_eval=-0.000 delta_w_squared=0.027\n",
      "    Pruner step took: 19.34s\n",
      "\n",
      "Evaluating model after epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05:17:13:53,921 DEBUG    [__init__.py:522] File _phrases_va_common.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/catalan_bench/phrases_va could not be loaded\n",
      "2024-11-05:17:13:56,645 DEBUG    [__init__.py:522] File _phrases_es_common.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/spanish_bench/phrases_es could not be loaded\n",
      "2024-11-05:17:14:06,778 DEBUG    [__init__.py:522] File winogenerated.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/model_written_evals/winogenerated could not be loaded\n",
      "2024-11-05:17:14:15,465 WARNING  [evaluator.py:270] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-11-05:17:14:15,467 DEBUG    [cache.py:33] requests-hellaswag-0shot-rank0-world_size1-tokenizer is not cached, generating...\n",
      "2024-11-05:17:14:15,468 INFO     [task.py:415] Building contexts for hellaswag on rank 0...\n",
      "100%|█████████████████████████████████████████| 10/10 [00:00<00:00, 1661.70it/s]\n",
      "2024-11-05:17:14:15,486 DEBUG    [evaluator.py:460] Task: hellaswag; number of requests on this rank: 40\n",
      "2024-11-05:17:14:15,487 INFO     [evaluator.py:489] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|██████████| 40/40 [00:00<00:00, 263.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for each task:\n",
      "    hellaswag : 30.000 (+-15.275)\n",
      "  Evaluation time: evaluation_time=25.2sec, Accuracy: 30.00% (+-15.28%)\n",
      "  Time: prune_time=19.3sec\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "num_epoch=4\n",
      "-----------------------\n",
      "Pruner step 1 (of 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05:17:14:36,935 WARNING  [huggingface.py:96] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "2024-11-05:17:14:36,936 INFO     [huggingface.py:483] Using model type 'default'\n",
      "2024-11-05:17:14:36,938 WARNING  [huggingface.py:277] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "2024-11-05:17:14:36,940 INFO     [evaluator.py:217] Using pre-initialized model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Calculated gradient in 18.43s\n",
      "    w_name='model.layers.0.mlp.gate_proj.weight' k_effective=64\n",
      "    _calc_grad_sample_block() took: 0.00s\n",
      "    _calc_hess_block() took: 0.00s\n",
      "    scaling=3.266e+07 cutoff=1.000e-12 Q_density=1.00000 Q_density_cutoff=0.54718\n",
      "    Solving with ConstrainedSASolver, problem_filename=PosixPath('.98345_241105_171436815142_f540d2661b6e42e28ac6a558714991b5.tmp')\n",
      "    n=128 best_E=731.490 elapsed_time=0.013\n",
      "    dL=0.000 dE=0.000 ridge_contribution=0.000 const=0.000 best_E=0.000 dL_eval=-0.000 delta_w_squared=0.005\n",
      "    Pruner step took: 18.58s\n",
      "\n",
      "Evaluating model after epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05:17:14:37,581 DEBUG    [__init__.py:522] File _phrases_va_common.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/catalan_bench/phrases_va could not be loaded\n",
      "2024-11-05:17:14:40,339 DEBUG    [__init__.py:522] File _phrases_es_common.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/spanish_bench/phrases_es could not be loaded\n",
      "2024-11-05:17:14:50,521 DEBUG    [__init__.py:522] File winogenerated.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/model_written_evals/winogenerated could not be loaded\n",
      "2024-11-05:17:14:58,284 WARNING  [evaluator.py:270] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-11-05:17:14:58,285 DEBUG    [cache.py:33] requests-hellaswag-0shot-rank0-world_size1-tokenizer is not cached, generating...\n",
      "2024-11-05:17:14:58,286 INFO     [task.py:415] Building contexts for hellaswag on rank 0...\n",
      "100%|█████████████████████████████████████████| 10/10 [00:00<00:00, 1475.36it/s]\n",
      "2024-11-05:17:14:58,304 DEBUG    [evaluator.py:460] Task: hellaswag; number of requests on this rank: 40\n",
      "2024-11-05:17:14:58,305 INFO     [evaluator.py:489] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|██████████| 40/40 [00:00<00:00, 264.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for each task:\n",
      "    hellaswag : 30.000 (+-15.275)\n",
      "  Evaluation time: evaluation_time=24.3sec, Accuracy: 30.00% (+-15.28%)\n",
      "  Time: prune_time=18.6sec\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "num_epoch=5\n",
      "-----------------------\n",
      "Pruner step 1 (of 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05:17:15:20,732 WARNING  [huggingface.py:96] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "2024-11-05:17:15:20,735 INFO     [huggingface.py:483] Using model type 'default'\n",
      "2024-11-05:17:15:20,737 WARNING  [huggingface.py:277] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "2024-11-05:17:15:20,740 INFO     [evaluator.py:217] Using pre-initialized model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Calculated gradient in 19.35s\n",
      "    w_name='model.layers.0.mlp.gate_proj.weight' k_effective=64\n",
      "    _calc_grad_sample_block() took: 0.00s\n",
      "    _calc_hess_block() took: 0.00s\n",
      "    scaling=3.791e+07 cutoff=1.000e-12 Q_density=1.00000 Q_density_cutoff=0.49567\n",
      "    Solving with ConstrainedSASolver, problem_filename=PosixPath('.98345_241105_171520600940_233291fc4d684397aade90084cb7c5ed.tmp')\n",
      "    n=128 best_E=50.679 elapsed_time=0.014\n",
      "    dL=0.000 dE=0.000 ridge_contribution=0.000 const=0.000 best_E=0.000 dL_eval=-0.000 delta_w_squared=0.001\n",
      "    Pruner step took: 19.51s\n",
      "\n",
      "Evaluating model after epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05:17:15:21,477 DEBUG    [__init__.py:522] File _phrases_va_common.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/catalan_bench/phrases_va could not be loaded\n",
      "2024-11-05:17:15:24,217 DEBUG    [__init__.py:522] File _phrases_es_common.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/spanish_bench/phrases_es could not be loaded\n",
      "2024-11-05:17:15:34,404 DEBUG    [__init__.py:522] File winogenerated.yaml in /Users/gilir/git/pruning-nns/lm-evaluation-harness/lm_eval/tasks/model_written_evals/winogenerated could not be loaded\n",
      "2024-11-05:17:15:43,621 WARNING  [evaluator.py:270] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-11-05:17:15:43,623 DEBUG    [cache.py:33] requests-hellaswag-0shot-rank0-world_size1-tokenizer is not cached, generating...\n",
      "2024-11-05:17:15:43,624 INFO     [task.py:415] Building contexts for hellaswag on rank 0...\n",
      "100%|█████████████████████████████████████████| 10/10 [00:00<00:00, 1784.73it/s]\n",
      "2024-11-05:17:15:43,641 DEBUG    [evaluator.py:460] Task: hellaswag; number of requests on this rank: 40\n",
      "2024-11-05:17:15:43,642 INFO     [evaluator.py:489] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|██████████| 40/40 [00:00<00:00, 289.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for each task:\n",
      "    hellaswag : 30.000 (+-15.275)\n",
      "  Evaluation time: evaluation_time=25.7sec, Accuracy: 30.00% (+-15.28%)\n",
      "  Time: prune_time=19.5sec\n",
      "\n",
      "Experiment took: 3.64min\n"
     ]
    }
   ],
   "source": [
    "experiment_start_time = time.time()\n",
    "\n",
    "valid_accuracies = [valid_accuracy]\n",
    "prune_times = [0.0]\n",
    "evaluation_times = [evaluation_time]\n",
    "for num_epoch in range(1, pruner_num_epochs + 1):\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{num_epoch=}\")\n",
    "    start_time = time.time()\n",
    "    w_names_step = np.random.permutation(w_names_step)\n",
    "    prune_loop(\n",
    "        prune_dataloader,\n",
    "        model,\n",
    "        pruner,\n",
    "        input_device,\n",
    "        w_names_step,\n",
    "        verbose=1 if verbose else None,\n",
    "    )\n",
    "    prune_time = time.time() - start_time\n",
    "\n",
    "    print(f\"\\nEvaluating model after epoch {num_epoch}:\")\n",
    "    valid_accuracy, evaluation_time, _ = evaluate_model_tasks(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        verbose=True if verbose else False,\n",
    "        batch_size=batch_size_evaluation,\n",
    "        device=device,\n",
    "        **evaluate_model_tasks_args,\n",
    "    )\n",
    "    print(f\"  Time: {prune_time=:.1f}sec\\n\")\n",
    "\n",
    "    valid_accuracies.append(valid_accuracy)\n",
    "    prune_times.append(prune_time)\n",
    "    evaluation_times.append(evaluation_time)\n",
    "\n",
    "experiment_time = time.time() - experiment_start_time\n",
    "print(f\"Experiment took: {experiment_time/60:.2f}min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92380314-084f-414a-a098-6579d28553a3",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e12dfa12-4d86-4d15-a794-d39d76e3c392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the evolution of the validation accuracy across epochs\n",
    "plt.figure()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation accuracy [%]\")\n",
    "plt.axhline(y=valid_accuracies[0], linestyle=\"--\", label=f\"{init_method}\", color=\"b\")\n",
    "plt.axhline(y=unpruned_valid_accuracy, linestyle=\"--\", label=f\"No pruning\", color=\"k\")\n",
    "plt.plot(valid_accuracies, label=\"iCBS (ours)\", linestyle=\"--\", color=\"r\")\n",
    "plt.legend(loc=\"lower right\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prunes",
   "language": "python",
   "name": "prunes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
